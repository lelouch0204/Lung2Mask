{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport cv2\nfrom PIL import Image\nimport random\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.utils import make_grid, save_image\nimport torchvision.transforms.functional as TF\nfrom torchvision import transforms\nimport albumentations as A","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:49:42.015182Z","iopub.execute_input":"2022-01-25T13:49:42.015599Z","iopub.status.idle":"2022-01-25T13:49:46.491255Z","shell.execute_reply.started":"2022-01-25T13:49:42.015516Z","shell.execute_reply":"2022-01-25T13:49:46.490162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_path = '../input/chest-xray-masks-and-labels/Lung Segmentation/'\nimg_dir = root_path + 'CXR_png/'\nmask_dir = root_path + 'masks/'","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:50:57.784222Z","iopub.execute_input":"2022-01-25T13:50:57.7846Z","iopub.status.idle":"2022-01-25T13:50:57.79035Z","shell.execute_reply.started":"2022-01-25T13:50:57.784569Z","shell.execute_reply":"2022-01-25T13:50:57.788797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fname_imgs = os.listdir(img_dir)\nfname_masks = os.listdir(mask_dir)\nprint(\"Images:\", len(fname_imgs), \"\\nMasks:\", len(fname_masks))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:50:58.209602Z","iopub.execute_input":"2022-01-25T13:50:58.210024Z","iopub.status.idle":"2022-01-25T13:50:58.849708Z","shell.execute_reply.started":"2022-01-25T13:50:58.209992Z","shell.execute_reply":"2022-01-25T13:50:58.848383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = Image.open('../input/chest-xray-masks-and-labels/Lung Segmentation/CXR_png/CHNCXR_0001_0.png')\nprint(img.size)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:50:59.459328Z","iopub.execute_input":"2022-01-25T13:50:59.459722Z","iopub.status.idle":"2022-01-25T13:50:59.526997Z","shell.execute_reply.started":"2022-01-25T13:50:59.45969Z","shell.execute_reply":"2022-01-25T13:50:59.525855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating our custom Dataset and DataLoader","metadata":{}},{"cell_type":"code","source":"class LungDataset(Dataset):\n    def __init__(self, img_dir, mask_dir, mask_list, train=True, tfms=None):\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.mask_list = mask_list\n        self.train = train\n        self.tfms = tfms\n        \n        self.train_mask_list, self.val_mask_list = train_test_split(self.mask_list, test_size=0.2, random_state=42)\n        \n    def __len__(self):\n        if self.train:\n            return len(self.train_mask_list)\n        else:\n            return len(self.val_mask_list)\n    \n    def __getitem__(self, idx):\n        if self.train:\n            mask_name = self.train_mask_list[idx]\n        else:\n            mask_name = self.val_mask_list[idx]\n        \n        img_name = mask_name.replace('_mask.png', '.png') if 'mask' in mask_name else mask_name\n        mask_path = self.mask_dir + mask_name\n        img_path = self.img_dir + img_name \n        \n        img = Image.open(img_path).convert('L')\n        mask = Image.open(mask_path).convert('L')\n        \n        if self.train:\n            if random.random() > 0.5:\n                img = TF.hflip(img)\n                mask = TF.hflip(mask)\n            \n            if random.random() > 0.5:\n                img = TF.vflip(img)\n                mask = TF.vflip(mask)\n                \n            if random.random() > 0.8:\n                angles = range(-90, 105, 15)\n                angle = random.choice(angles)\n                img = TF.rotate(img, angle)\n                mask = TF.rotate(mask, angle)\n                \n        if self.tfms is not None:\n            img = self.tfms['img'](img)\n            mask = self.tfms['mask'](mask)\n            \n            ret_value = {'image': img, 'mask': mask}\n            return ret_value","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:51:01.47827Z","iopub.execute_input":"2022-01-25T13:51:01.478633Z","iopub.status.idle":"2022-01-25T13:51:01.494273Z","shell.execute_reply.started":"2022-01-25T13:51:01.478601Z","shell.execute_reply":"2022-01-25T13:51:01.493027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfms_img = transforms.Compose([ transforms.Resize((256, 256)),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5,), (0.5,))\n                              ])\n\ntfms_mask = transforms.Compose([ transforms.Resize((256, 256)),\n                               transforms.ToTensor(),\n                              ])\n\ntfms = {'img': tfms_img, 'mask': tfms_mask}\n\ntrain_dataset = LungDataset(img_dir, mask_dir, fname_masks, train=True, tfms=tfms)\nval_dataset = LungDataset(img_dir, mask_dir, fname_masks, train=False, tfms=tfms)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:51:02.105841Z","iopub.execute_input":"2022-01-25T13:51:02.106279Z","iopub.status.idle":"2022-01-25T13:51:02.116483Z","shell.execute_reply.started":"2022-01-25T13:51:02.106247Z","shell.execute_reply":"2022-01-25T13:51:02.115191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True, num_workers=2)\nval_loader = DataLoader(dataset=val_dataset, batch_size=4, shuffle=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:51:02.745315Z","iopub.execute_input":"2022-01-25T13:51:02.745726Z","iopub.status.idle":"2022-01-25T13:51:02.751845Z","shell.execute_reply.started":"2022-01-25T13:51:02.745674Z","shell.execute_reply":"2022-01-25T13:51:02.750534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(img, mask=False):\n    img = img.cpu().clone().detach().numpy()\n    img = img.transpose(1, 2, 0)\n    print(img.shape)\n    \n    if mask:\n        img = img * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n    else:\n        img = img * np.array((1.0, 1.0, 1.0))\n    \n    img  = img.clip(0, 1)\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:51:03.268909Z","iopub.execute_input":"2022-01-25T13:51:03.269295Z","iopub.status.idle":"2022-01-25T13:51:03.276502Z","shell.execute_reply.started":"2022-01-25T13:51:03.269264Z","shell.execute_reply":"2022-01-25T13:51:03.275196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:51:03.772754Z","iopub.execute_input":"2022-01-25T13:51:03.773617Z","iopub.status.idle":"2022-01-25T13:51:03.788505Z","shell.execute_reply.started":"2022-01-25T13:51:03.773572Z","shell.execute_reply":"2022-01-25T13:51:03.787035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (15,6))\nfor ith_batch, sample_batched in enumerate(train_loader):\n    print(ith_batch, sample_batched['image'].size(), sample_batched['mask'].size())\n    \n    for index in range(2):\n        ax = fig.add_subplot(2, 2 , index + 1)  # subplot index starts from 1\n        plt.imshow(imshow(sample_batched['image'][index]))\n        ax = fig.add_subplot(2, 2, index + 3)\n        plt.imshow(imshow(sample_batched['mask'][index]))\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:51:04.097055Z","iopub.execute_input":"2022-01-25T13:51:04.097614Z","iopub.status.idle":"2022-01-25T13:51:08.296004Z","shell.execute_reply.started":"2022-01-25T13:51:04.097569Z","shell.execute_reply":"2022-01-25T13:51:08.294734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Architecture of the Pix2Pix","metadata":{}},{"cell_type":"code","source":"class DownConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel=4, strides=2, padding=1, activation=True, batchnorm=True):\n        \"\"\"\n        The paper uses:\n        - Convolutions of 4x4 spatial filters applied with stride of 2\n        - Encoder downsampling by a factor of 2 \n        \"\"\"\n        super().__init__()\n        self.activation = activation\n        self.batchnorm = batchnorm\n        \n        self.conv = nn.Conv2d(in_channels, out_channels, kernel, strides, padding)\n        \n        if self.batchnorm:\n            self.bn = nn.BatchNorm2d(out_channels)\n            \n        if self.activation:\n            self.relu = nn.LeakyReLU(0.2)\n        \n    def forward(self, x):\n        x = self.conv(x)\n        if self.batchnorm:\n            x = self.bn(x)\n        if self.activation:\n            x = self.relu(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:51:08.29796Z","iopub.execute_input":"2022-01-25T13:51:08.298395Z","iopub.status.idle":"2022-01-25T13:51:08.310193Z","shell.execute_reply.started":"2022-01-25T13:51:08.298343Z","shell.execute_reply":"2022-01-25T13:51:08.308624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UpConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel=4, strides=2, padding=1, activation=True, batchnorm=True, dropout=False):\n        super().__init__()\n        self.activation = activation\n        self.batchnorm = batchnorm\n        self.dropout = dropout \n        \n        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, kernel, strides, padding)\n        \n        if self.batchnorm:\n            self.bn = nn.BatchNorm2d(out_channels)\n            \n        if self.activation:\n            self.relu = nn.ReLU(True)\n            \n        if self.dropout:\n            self.drop = nn.Dropout2d(0.5)\n            \n    def forward(self, x):\n        x = self.deconv(x)\n        if self.batchnorm:\n            x = self.bn(x)\n        if self.relu:\n            x = self.relu(x)\n        if self.dropout:\n            x = self.drop(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:51:08.313579Z","iopub.execute_input":"2022-01-25T13:51:08.314434Z","iopub.status.idle":"2022-01-25T13:51:08.326863Z","shell.execute_reply.started":"2022-01-25T13:51:08.314389Z","shell.execute_reply":"2022-01-25T13:51:08.325526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, input_channels):\n        super().__init__()\n        self.d1 = DownConv(input_channels, 64, batchnorm=False)\n        self.d2 = DownConv(64, 128)\n        self.d3 = DownConv(128, 256)\n        self.d4 = DownConv(256, 512)\n        self.final = nn.Conv2d(512, 1, kernel_size=1)\n        \n    def forward(self, x, y):\n        x = torch.cat([x, y], axis=1)\n        x0 = self.d1(x)\n        x1 = self.d2(x0)\n        x2 = self.d3(x1)\n        x3 = self.d4(x2)\n        xn = self.final(x3)\n        return xn","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:51:08.328778Z","iopub.execute_input":"2022-01-25T13:51:08.329251Z","iopub.status.idle":"2022-01-25T13:51:08.340741Z","shell.execute_reply.started":"2022-01-25T13:51:08.329207Z","shell.execute_reply":"2022-01-25T13:51:08.339398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, input_channels, output_channels):\n        super().__init__()\n        \n        self.encoders = [\n            DownConv(input_channels, 64, batchnorm=False), #batch_size x 64 x 128 x 128\n            DownConv(64, 128),\n            DownConv(128, 256), \n            DownConv(256, 512),\n            DownConv(512, 512),\n            DownConv(512, 512),\n            DownConv(512, 512),\n            DownConv(512, 512, batchnorm=False)\n        ]\n        \n        self.decoders = [\n            UpConv(512, 512, dropout=True),\n            UpConv(1024, 512, dropout=True),\n            UpConv(1024, 512, dropout=True),\n            UpConv(1024, 512),\n            UpConv(1024, 256),\n            UpConv(512, 128),\n            UpConv(256, 64)\n        ]\n        \n        self.dec_channels = [512, 512, 512, 512, 256, 128, 64]\n        self.final_conv = nn.ConvTranspose2d(64, output_channels, kernel_size=4, stride=2, padding=1)\n        self.tanh = nn.Tanh()\n        \n        self.encoders = nn.ModuleList(self.encoders)\n        self.decoders = nn.ModuleList(self.decoders)\n    \n    def forward(self, x):\n        skip_conns = []\n        for encoder in self.encoders:\n            x = encoder(x)\n            skip_conns.append(x)\n            \n        skip_conns = list(reversed(skip_conns[:-1]))\n        decoders = self.decoders[:-1]\n        \n        for decoder, skip in zip(decoders, skip_conns):\n            x = decoder(x)\n            # print(x.shape, skip.shape)\n            x = torch.cat((x, skip), axis=1)\n\n        x = self.decoders[-1](x)\n        # print(x.shape)\n        x = self.final_conv(x)\n        return self.tanh(x)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:51:08.342618Z","iopub.execute_input":"2022-01-25T13:51:08.343161Z","iopub.status.idle":"2022-01-25T13:51:08.360074Z","shell.execute_reply.started":"2022-01-25T13:51:08.343112Z","shell.execute_reply":"2022-01-25T13:51:08.358924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sanity_check():\n    x = torch.randn((1, 1, 256, 256))\n    y = torch.randn((1, 1, 256, 256))\n    gen1 = Generator(1, 1)\n    pred_gen = gen1(x)\n    print(\"Generator Output\", pred_gen.shape)\n    \nsanity_check()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:51:08.361968Z","iopub.execute_input":"2022-01-25T13:51:08.362506Z","iopub.status.idle":"2022-01-25T13:51:09.33718Z","shell.execute_reply.started":"2022-01-25T13:51:08.362448Z","shell.execute_reply":"2022-01-25T13:51:09.335917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\ndisc = Discriminator(input_channels=2).to(device)\ngen = Generator(input_channels=1, output_channels=1).to(device)\n\ndisc_opt = optim.Adam(disc.parameters(), lr=0.0001, betas=(0.5, 0.99))\ngen_opt = optim.Adam(gen.parameters(), lr=0.0001, betas=(0.5, 0.99))\n\nBCE = nn.BCEWithLogitsLoss()\nL1 = nn.L1Loss()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:19:30.408213Z","iopub.execute_input":"2022-01-25T14:19:30.408753Z","iopub.status.idle":"2022-01-25T14:19:30.982998Z","shell.execute_reply.started":"2022-01-25T14:19:30.408702Z","shell.execute_reply":"2022-01-25T14:19:30.981693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_disc(disc, gen, imgs, masks, loss, disc_opt):\n    disc.train()\n    \n    fake_masks = gen(imgs)\n    disc_real = disc(imgs, masks) #generate discriminator output for X-Ray and corresponding ground truth mask \n    disc_fake = disc(imgs, fake_masks.detach()) #generate disc output for X-Ray and produced mask\n    \n    #calculate the loss\n    disc_real_loss = BCE(disc_real, torch.ones_like(disc_real))\n    disc_fake_loss = BCE(disc_real, torch.zeros_like(disc_fake))\n    disc_loss = (disc_real_loss+disc_fake_loss)/2\n    \n    disc.zero_grad()\n    \n    disc_loss.backward()\n    \n    disc_opt.step()\n    \n    return fake_masks, disc_loss","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:20:24.301619Z","iopub.execute_input":"2022-01-25T14:20:24.302238Z","iopub.status.idle":"2022-01-25T14:20:24.311571Z","shell.execute_reply.started":"2022-01-25T14:20:24.30217Z","shell.execute_reply":"2022-01-25T14:20:24.310414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_gen(disc, gen, imgs, masks, fake_masks, loss_bce, loss_l1, gen_opt):\n    gen.train()\n    \n    disc_fake = disc(imgs, fake_masks.detach())\n    \n    gen_fake_loss = BCE(disc_fake, torch.ones_like(disc_fake))\n    l1 = L1(fake_masks, masks)*100\n    gen_loss = gen_fake_loss + l1\n    \n    gen_opt.zero_grad()\n    gen_loss.backward()\n    gen_opt.step()\n    \n    return gen_loss","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:23:31.47339Z","iopub.execute_input":"2022-01-25T14:23:31.473819Z","iopub.status.idle":"2022-01-25T14:23:31.482063Z","shell.execute_reply.started":"2022-01-25T14:23:31.473773Z","shell.execute_reply":"2022-01-25T14:23:31.48073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_img(gen, valid_dataloader, device, epoch_num, dir_path):\n    if os.path.exists(dir_path) == False:\n        os.makedirs(dir_path)\n        \n    sample = next(iter(valid_dataloader))\n    imgs = sample['image']\n    masks = sample['mask']\n    batch_size = imgs.shape[0]\n    imgs = imgs.to(device)\n    masks = masks.to(device)\n    \n    gen.eval()\n    \n    with torch.no_grad():\n        fake_masks = gen(imgs)\n        fake_mask_grid = make_grid(fake_masks, nrow=4)\n        real_mask_grid = make_grid(masks, nrow=4)\n        \n        save_image(fake_mask_grid, dir_path + f'/fake_masks_{epoch_num}.png')\n        save_image(real_mask_grid, dir_path + f'/real_masks_{epoch_num}.png')\n        print(\"Saved intermediate images\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:27:47.109622Z","iopub.execute_input":"2022-01-25T14:27:47.110003Z","iopub.status.idle":"2022-01-25T14:27:47.119042Z","shell.execute_reply.started":"2022-01-25T14:27:47.109972Z","shell.execute_reply":"2022-01-25T14:27:47.117441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(gen,\n         disc,\n         train_dataloader,\n         val_dataloader,\n         loss_bce,\n         loss_l1,\n         num_epochs,\n         gen_opt,\n         disc_opt,\n         device,\n         dir_path\n         ):\n    gen_losses = []\n    disc_losses = []\n    \n    num_steps = len(train_dataloader)\n    step = 0\n    \n    for epoch in range(num_epochs):\n        for i, sample in enumerate(train_dataloader):\n            imgs = sample['image'].to(device)\n            masks = sample['mask'].to(device)\n            ##print(masks.size())\n            \n            fake_masks, disc_loss = train_disc(disc, gen, imgs, masks, loss_bce, disc_opt)\n            gen_loss = train_gen(disc, gen, imgs, masks, fake_masks, loss_bce, loss_l1, gen_opt)\n            \n            if i%20 == 0:\n                disc_losses.append(disc_loss.item())\n                gen_losses.append(gen_loss.item())\n                \n                print('Epoch [{}/{}], Step [{}/{}], Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(epoch, num_epochs, i, num_steps, disc_loss.item(), gen_loss.item()))\n                step+=1\n                \n            save_img(gen, val_dataloader, device, epoch, dir_path)\n            \n    ret_value = {\"disc_loss\": disc_losses, \"gen_loss\": gen_losses}\n    return ret_value","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:27:47.927699Z","iopub.execute_input":"2022-01-25T14:27:47.928097Z","iopub.status.idle":"2022-01-25T14:27:47.938313Z","shell.execute_reply.started":"2022-01-25T14:27:47.928051Z","shell.execute_reply":"2022-01-25T14:27:47.936998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = train(gen, disc, train_loader, val_loader, BCE, L1, 100, gen_opt, disc_opt, device, 'results')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:27:49.577383Z","iopub.execute_input":"2022-01-25T14:27:49.577768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(gen.state_dict(), '/checkpoints/gen_lung2mask_1.pth')\ntorch.save(disc.state_dict(), '/checkpoints/disc_lung2mask_1.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history['disc_loss'], '-')\nplt.plot(history['gen_loss'], '-')\nplt.xlabel('Epoch Number')\nplt.ylabel('Loss')\nplt.legend(['Discriminator Loss', 'Generator Loss'])\nplt.title('Loss during training')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}